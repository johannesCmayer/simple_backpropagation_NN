{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_openml\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import random\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data, y_data = fetch_openml('mnist_784', version=1, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_int_onehot(int_to_encode, num_classes):\n",
    "    vec = np.zeros(num_classes)\n",
    "    vec[int_to_encode] = 1\n",
    "    return vec\n",
    "\n",
    "y_data = y_data.astype(np.int64)\n",
    "y_one_hot = np.array([encode_int_onehot(y, np.max(y_data) + 1) for y in y_data.astype(np.int64)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 10)\n"
     ]
    }
   ],
   "source": [
    "print(y_one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_side_length = int(np.sqrt(len(x_data[0])))\n",
    "for i in range(1):\n",
    "    plt.imshow(x_data[i].reshape(image_side_length, image_side_length))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hinge_loss(pred, y_one_hot):\n",
    "    correct_class = np.argmax(y_one_hot)\n",
    "    value_correct_class = pred[correct_class]\n",
    "    loss = np.maximum(0, pred - value_correct_class + 1)\n",
    "    loss[correct_class] = 0\n",
    "    return np.sum(loss)\n",
    "\n",
    "\n",
    "class LinearClassifier():\n",
    "    def __init__(self, input_size, output_size):\n",
    "        self.weights = np.random.rand(output_size, input_size)\n",
    "\n",
    "    def eval(self, inputs, overwrite_weights=None):\n",
    "        active_weights = self.weights\n",
    "        if overwrite_weights is not None:\n",
    "            active_weights = overwrite_weights\n",
    "        return np.matmul(active_weights, inputs)        \n",
    "\n",
    "    def outputs_to_probabilities(self, outputs):\n",
    "        squashed_result = outputs / np.amax(outputs)\n",
    "        unnormal_probabilities = np.exp(squashed_result)\n",
    "        if unnormal_probabilities[unnormal_probabilities == np.inf].any():\n",
    "            raise Exception('There are infinity values in result after exponentiation. Weights might be initialized to high. Value is {}'\n",
    "                            .format(unnormal_probabilities))\n",
    "        probabilities = unnormal_probabilities / sum(unnormal_probabilities)\n",
    "        return probabilities\n",
    "    \n",
    "    def batch_eval(self, inputs, overwrite_weights=None):\n",
    "        return [self.eval(i, overwrite_weights=overwrite_weights) for i in inputs]\n",
    "\n",
    "    def cost(self, output, one_hot_target, loss_func=hinge_loss):        \n",
    "        return loss_func(output, one_hot_target)\n",
    "    \n",
    "    def cost_vrt(self, outputs, one_hot_targets, loss_func=hinge_loss):\n",
    "        cost = 0\n",
    "        for i, t in zip(outputs, one_hot_targets):\n",
    "            cost += self.cost(i, t, loss_func=loss_func)\n",
    "        return cost / len(outputs)\n",
    "    \n",
    "    def gradient_vrt(self, inputs, one_hot_targets, dx=0.01, batch_size=None):        \n",
    "        data = zip(inputs, one_hot_targets)\n",
    "        if batch_size:\n",
    "            data = random.sample(list(data), batch_size)\n",
    "        weight_mat_shape = self.weights.shape\n",
    "        weight_mat_size = np.size(self.weights)\n",
    "        total_gradient = np.zeros(weight_mat_shape)\n",
    "        cnt = 0\n",
    "        for sample_input, target in data:\n",
    "            sample_gradient = []            \n",
    "            #print(\"\\033[F\")\n",
    "            print('{} / {}'.format(cnt, len(inputs)))\n",
    "            cnt += 1\n",
    "            for i in range(weight_mat_size):\n",
    "                if i % 100 == 0:\n",
    "                    print('{} / {}'.format(i, weight_mat_size), end='\\r')\n",
    "                nudge_weight_mat = np.zeros(weight_mat_size)\n",
    "                nudge_weight_mat[i] = dx                \n",
    "                nudge_weight_mat = nudge_weight_mat.reshape(weight_mat_shape)  \n",
    "                nudged_weight_mat = self.weights + nudge_weight_mat                \n",
    "                nudged_out = self.eval(sample_input, overwrite_weights=nudged_weight_mat)\n",
    "                out = self.eval(sample_input)\n",
    "                \n",
    "                sample_gradient.append(self.cost(nudged_out, one_hot_targets) - self.cost(out, one_hot_targets))\n",
    "                # print('n_out', nudged_out)\n",
    "                # print('out', out)\n",
    "                # print('diff', self.cost(nudged_out, one_hot_targets) - self.cost(out, one_hot_targets))\n",
    "                # #print('diff weights', sum(nudged_weight_mat), sum(self.weights))\n",
    "                # raise Exception()\n",
    "            total_gradient += np.reshape(sample_gradient, weight_mat_shape)\n",
    "        #print('pre noraml total grad', total_gradient)\n",
    "        return total_gradient / np.size(data)\n",
    "        \n",
    "    def train(self, inputs, one_hot_targets, epochs=1, learning_rate=0.01, verbose=False, batch_size=None):\n",
    "        prev_loss = None\n",
    "        for ep in range(epochs):\n",
    "            gradient = self.gradient_vrt(inputs, one_hot_targets, batch_size=batch_size)            \n",
    "            self.weights = self.weights - gradient * learning_rate\n",
    "            if verbose:\n",
    "                #print('gradient:', gradient)\n",
    "                print('gradient max val:', np.max(gradient))\n",
    "                current_loss = self.cost_vrt(self.batch_eval(inputs), one_hot_targets)\n",
    "                print('loss:', current_loss)\n",
    "                if prev_loss:\n",
    "                    print('loss improvment:', prev_loss - current_loss)\n",
    "                prev_loss = current_loss\n",
    "                print('----------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc = LinearClassifier(x_data[0].size, y_one_hot[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1\n0 / 7840\r100 / 7840\r200 / 7840\r300 / 7840\r400 / 7840\r500 / 7840\r600 / 7840\r700 / 7840\r800 / 7840\r900 / 7840\r1000 / 7840\r1100 / 7840\r1200 / 7840\r1300 / 7840\r1400 / 7840\r1500 / 7840\r1600 / 7840\r1700 / 7840\r1800 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900 / 7840\r2000 / 7840\r2100 / 7840\r2200 / 7840\r2300 / 7840\r2400 / 7840\r2500 / 7840\r2600 / 7840\r2700 / 7840\r2800 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2900 / 7840\r3000 / 7840\r3100 / 7840\r3200 / 7840\r3300 / 7840\r3400 / 7840\r3500 / 7840\r3600 / 7840\r3700 / 7840\r3800 / 7840\r3900 / 7840\r4000 / 7840\r4100 / 7840\r4200 / 7840\r4300 / 7840"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r4400 / 7840\r4500 / 7840\r4600 / 7840\r4700 / 7840\r4800 / 7840\r4900 / 7840\r5000 / 7840\r5100 / 7840\r5200 / 7840\r5300 / 7840\r5400 / 7840\r5500 / 7840\r5600 / 7840\r5700 / 7840\r5800 / 7840\r5900 / 7840\r6000 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6100 / 7840\r6200 / 7840\r6300 / 7840\r6400 / 7840\r6500 / 7840\r6600 / 7840\r6700 / 7840\r6800 / 7840\r6900 / 7840\r7000 / 7840\r7100 / 7840\r7200 / 7840\r7300 / 7840\r7400 / 7840\r7500 / 7840\r7600 / 7840\r7700 / 7840\r7800 / 7840\rgradient max val: 0.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.0\n----------\n0 / 1\n0 / 7840\r100 / 7840\r200 / 7840\r300 / 7840\r400 / 7840\r500 / 7840\r600 / 7840\r700 / 7840\r800 / 7840\r900 / 7840\r1000 / 7840\r1100 / 7840\r1200 / 7840\r1300 / 7840\r1400 / 7840\r1500 / 7840\r1600 / 7840\r1700 / 7840\r1800 / 7840\r1900 / 7840"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r2000 / 7840\r2100 / 7840\r2200 / 7840\r2300 / 7840\r2400 / 7840\r2500 / 7840\r2600 / 7840\r2700 / 7840\r2800 / 7840\r2900 / 7840\r3000 / 7840\r3100 / 7840\r3200 / 7840\r3300 / 7840\r3400 / 7840\r3500 / 7840\r3600 / 7840\r3700 / 7840\r3800 / 7840\r3900 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 / 7840\r4100 / 7840\r4200 / 7840\r4300 / 7840\r4400 / 7840\r4500 / 7840\r4600 / 7840\r4700 / 7840\r4800 / 7840\r4900 / 7840\r5000 / 7840\r5100 / 7840\r5200 / 7840\r5300 / 7840\r5400 / 7840\r5500 / 7840\r5600 / 7840\r5700 / 7840\r5800 / 7840\r5900 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 / 7840\r6100 / 7840\r6200 / 7840\r6300 / 7840\r6400 / 7840\r6500 / 7840\r6600 / 7840\r6700 / 7840\r6800 / 7840\r6900 / 7840\r7000 / 7840\r7100 / 7840\r7200 / 7840\r7300 / 7840\r7400 / 7840\r7500 / 7840\r7600 / 7840\r7700 / 7840\r7800 / 7840\rgradient max val:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.0\nloss: 0.0\n----------\n0 / 1\n0 / 7840\r100 / 7840\r200 / 7840\r300 / 7840\r400 / 7840\r500 / 7840\r600 / 7840\r700 / 7840\r800 / 7840\r900 / 7840\r1000 / 7840\r1100 / 7840\r1200 / 7840\r1300 / 7840\r1400 / 7840\r1500 / 7840\r1600 / 7840\r1700 / 7840\r1800 / 7840"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r1900 / 7840\r2000 / 7840\r2100 / 7840\r2200 / 7840\r2300 / 7840\r2400 / 7840\r2500 / 7840\r2600 / 7840\r2700 / 7840\r2800 / 7840\r2900 / 7840\r3000 / 7840\r3100 / 7840\r3200 / 7840\r3300 / 7840\r3400 / 7840\r3500 / 7840\r3600 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3700 / 7840\r3800 / 7840\r3900 / 7840\r4000 / 7840\r4100 / 7840\r4200 / 7840\r4300 / 7840\r4400 / 7840\r4500 / 7840\r4600 / 7840\r4700 / 7840\r4800 / 7840\r4900 / 7840\r5000 / 7840\r5100 / 7840\r5200 / 7840\r5300 / 7840\r5400 / 7840\r5500 / 7840\r5600 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5700 / 7840\r5800 / 7840\r5900 / 7840\r6000 / 7840\r6100 / 7840\r6200 / 7840\r6300 / 7840\r6400 / 7840\r6500 / 7840\r6600 / 7840\r6700 / 7840\r6800 / 7840\r6900 / 7840\r7000 / 7840\r7100 / 7840\r7200 / 7840\r7300 / 7840\r7400 / 7840\r7500 / 7840\r7600 / 7840\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7700 / 7840\r7800 / 7840\rgradient max val: 0.0\nloss: 0.0\n----------\n5\n5\n4% Classified correctly\n"
     ]
    }
   ],
   "source": [
    "def run():    \n",
    "    lc.train(x_data[:1], y_one_hot[:1], verbose=True, batch_size=None, epochs=3, learning_rate=0.01)\n",
    "    r = lc.eval(x_data[0])\n",
    "    \n",
    "    print(np.argmax(r))\n",
    "    print(np.argmax(y_one_hot[0]))\n",
    "    \n",
    "    idx_val = 100\n",
    "    val_res = []\n",
    "    for x, y in zip(x_data[:idx_val], y_one_hot[:idx_val]):\n",
    "        val_res.append(np.argmax(lc.eval(x)) == np.argmax(y))\n",
    "    correct_classified = int(sum(val_res) / len(val_res) * 100)\n",
    "    print('{}% Classified correctly'.format(correct_classified))\n",
    "    \n",
    "\n",
    "run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 3)\n(3,)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,0]])\n",
    "b = np.array([-0,2,1])\n",
    "print(a.shape)\n",
    "print(b.shape)\n",
    "np.matmul(a, b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
